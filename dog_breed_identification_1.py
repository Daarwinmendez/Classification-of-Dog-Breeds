# -*- coding: utf-8 -*-
"""Dog_Breed_Identification-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c2dRJCK8zVnAthcUg_SClDTlYS_I5wRv

<h2>Darwin Mendez - 2023-0769</h2>
<h2 style="color: blue; text-align: center;">Deep Learning</h2>
"""

!pip install tf_keras

from google.colab import drive

# 1. Montar mi Drive
drive.mount('/content/drive')
import numpy as np

"""# Clasificación End-to-End Multiclase de Razas de Perros

Este cuaderno construye un clasificador de imágenes de principio a fin utilizando TensorFlow 2.0 y TensorFlow Hub.

## 1. Problema

Identificar la raza de un perro dada una imagen del mismo.

Cuando estoy sentado en la cafetería y tomo una foto de un perro, quiero saber de qué raza es.

## 2. Datos

Los datos que estamos utilizando provienen de la competencia de identificación de razas de perros de Kaggle.

https://www.kaggle.com/c/dog-breed-identification

## 3. Evaluación

La evaluación consiste en un archivo con probabilidades de predicción para cada imagen de prueba de raza.

## 4. Características

Algunas informaciones sobre los datos:

* Estamos trabajando con imágenes (datos no estructurados), por lo que probablemente lo mejor sea usar deep/transfer learning.
* Hay 120 razas de perros (esto significa que existen 120 clases diferentes).
* Hay alrededor de 10,000+ imágenes en el conjunto de entrenamiento (estas imágenes tienen etiquetas).
"""

# Unzip the data folder
#!unzip "drive/MyDrive/Dog Vision/dog-breed-identification.zip"  -d "drive/MyDrive/Dog Vision"

"""## Preparar nuestro espacio de trabajo
* Importar TensorFlow ✅
* Importar TensorFlow Hub ✅
* Asegurarse de que estamos usando una GPU
"""

# Commented out IPython magic to ensure Python compatibility.
# Import TF 2.x

try:
  # %tensorflow_version only exists in Colab
#   %tensorflow_version 2.x
  #%tensorflow_hub_version 0.7x
except Exception:
  pass

# Import nessecary tools
import tensorflow as tf
import tensorflow_hub as hub
import matplotlib.pyplot as plt
import tf_keras
print("TF version:", tf.__version__)
print("TF Hub version:", hub.__version__)
print("\nGPU", "available" if tf.config.list_physical_devices("GPU") else "not available ):")

"""## Preparando nuestros Datos (Convirtiéndolos en tensores)

Con todos los modelos de machine learning, nuestros datos deben estar en formato numérico. Así que eso es lo que haremos (representaciones numéricas).

"""

# Checkout the labels of our data

import pandas as pd
#/content/drive/MyDrive/Dog Vision/labels.csv
labels_csv = pd.read_csv("/content/drive/MyDrive/Dog Vision/labels.csv")
labels_csv.describe()

labels_csv.head()

labels_csv["breed"].value_counts()

plt.style.available

# How many images are there of each bread
plt.style.use('fivethirtyeight')
fig, ax = plt.subplots(figsize=(22,10))
labels_csv["breed"].value_counts().plot.bar(ax=ax)


ax.set(
    title="Breed Count",
    xlabel="Breed",
    ylabel="Count"
)

plt.tight_layout()
plt.show()

labels_csv["breed"].value_counts().median()

# view image inside the notebook.

from IPython.display import Image

Image("drive/My Drive/Dog Vision/train/000bec180eb18c7604dcecc8fe0dba07.jpg")

"""### Obteniendo Imágenes y sus etiquetas

Vamos a obtener una lista de las rutas de nuestras imágenes

"""

labels_csv.head()

filenames = ["/content/drive/My Drive/Dog Vision/train/" + fname + ".jpg" for fname in labels_csv["id"]]

filenames[:3]

# Check whether nuber of filenames matches number of actual image files
import os

if len(os.listdir("/content/drive/MyDrive/Dog Vision/train")) == len(filenames):
  print("Filenames match actual amount of data")
else:
  print("Filenames do not match actual amount of data")

from IPython.display import Image
# One check
Image(filenames[1000])



"""Let's prepare the labels"""

labels = labels_csv["breed"].to_numpy()
labels

# See if number of labels matches the number of filenames

if len(labels) == len(filenames):
  print("Number of labels matches number of filenames!")
else:
  print("Number of labels does not match number of filenames!")

# Find unique label values
unique_breeds = np.unique(labels)

len(unique_breeds)

unique_breeds

# turn a single row i[nto an array of booleans
labels[0] == unique_breeds

# Turn every label into a boolean array
boolean_labels = [label == unique_breeds for label in labels]

len(boolean_labels)

# Turning boolean arrays into integers
print(labels[0])
print(np.where(unique_breeds == labels[0]))
print(boolean_labels[0].argmax())
print(boolean_labels[0].astype(int))

print(labels[1])
print(boolean_labels[1].astype(int))

"""Since the dataset doesn't come with validatin set, we'll do it here."""

X = filenames
y = boolean_labels

len(X), len(y)

# Let's start experimenting with 1000 and then we'll increase as needed

NUM_IMAGES = 1000 #@param {type: "slider", min:1000, max:10000}

# let's split our data into train and validation sets
from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],
                                                  y[:NUM_IMAGES],
                                                  test_size=0.2,
                                                  random_state=42)

len(X_train), len(y_train), len(X_val), len(y_val)

X_train[:3], y_train[:3]

"""### Preprocesamiento de Imágenes (Convirtiendo imágenes en tensores)

Escribamos una función que haga varias cosas:
1. Tomar la ruta de un archivo de imagen.
2. Usar TensorFlow para leer el archivo y guardarlo en una variable `image`.
3. Convertir nuestra `image` (un jpg) en tensores.
4. Redimensionar la `image` a una forma de (244, 244).
5. Retornar la `image` modificada.

Antes de hacerlo, veamos cómo se ve al importar una imagen.
"""

# Converts image to Numpy array

from matplotlib.pyplot import imread

image = imread(filenames[33])
image.shape

r, g, b = image[0][0]
print(f"Red: {r}, Green: {g}, Blue: {b}")

image.max(), image.min()

#turn image into a tensor
tf.constant(image)[:2]

"""Ahora hagamos una función para preprocesarlas

1. Tomar la ruta de un archivo de imagen.
2. Usar TensorFlow para leer el archivo y guardarlo en una variable `image`.
3. Convertir nuestra `image` (un jpg) en tensores.
4. Normalizar la `image` de 0-255 a 0-1.
5. Redimensionar la `image` a una forma de (244, 244).
6. Retornar la `image` modificada.

"""

IMG_SIZE = 224

# Create a function for preprocessing images

def process_image(image_path:str, image_size=IMG_SIZE)-> tf.Tensor:
  """
    Takes an image file path and turns the image into a Tensor.
  """

  # read in an image file
  image = tf.io.read_file(image_path)

  # Turn the jpeg image into numerical Tensor with 3 color channels (Red, Green, Blue)
  image = tf.image.decode_jpeg(image, channels=3)

  # convert the colour channel values from 0-255 to 0-1 values
  image = tf.image.convert_image_dtype(image, tf.float32)

  # resize the image to our desired size (244, 244)
  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])

  return image

#process_image()

tensor = tf.io.read_file(filenames[22])

tensor = tf.image.decode_jpeg(tensor, channels=3)

tensor = tf.image.convert_image_dtype(tensor, tf.float32)
#tensor
tensor.dtype

"""## Convirtiendo nuestros datos en lotes

¿Por qué convertir nuestros datos en lotes?

Imagina que estás procesando más de 10,000 imágenes de una sola vez... es posible que no todas quepan en memoria.

Por eso procesamos alrededor de 32 imágenes a la vez (este es el tamaño del lote, el cual puedes ajustar manualmente si es necesario).

Para usar TensorFlow de manera efectiva, necesitamos que nuestros datos estén en forma de tuplas de tensores que se vean así: `(image, label)`
"""

# Create a function to return a tuple of tensors
def get_image_label(image_path, label):
  """
    Takes an image file path name and the associated label,
    processes the image and returns a tuple of (image, label).
  """
  image = process_image(image_path)
  return image, label

(process_image(X[0]), tf.constant(y[0]))

"""Ahora que tenemos una forma de convertir nuestros datos en tuplas de tensores con el formato: `(image, label)`, hagamos una función para convertir todos nuestros datos (x & y) en lotes.

"""

BATCH_SIZE = 32;

def create_data_batches(X, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):
  """
    Creates batches of data out of image (X) and label (y) pairs.
    Shuffles the data if it's training data but doesn't shuffle it if it's validation data.
    Also accepts test data as input (no labels).

  """

  # if the data is a test dataset, we probabbly don't have labels
  if test_data:
    print("Creating test data batches...")
    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # no labels
    data_batch = data.map(process_image).batch(BATCH_SIZE)
    # shuffle
    return data_batch

  # if the data is a valid dataset, we don't need to shuffle it
  elif valid_data:
    print("Creating validation data batches...")
    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths
                                               tf.constant(y))) # labels
    data_batch = data.map(get_image_label).batch(BATCH_SIZE)
    return data_batch
  else:
    print("Creating training data batches...")
    # Turn filepaths and labels into tensors
    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths
                                               tf.constant(y))) # labels

    # Shuffling
    data = data.shuffle(buffer_size=len(X))

    # Create (image, label) tuples (also turns the image patch into a preprocessed image)
    data_batch = data.map(get_image_label).batch(BATCH_SIZE)
    return data_batch

# Create training and validation data batches
train_data = create_data_batches(X_train, y_train)
val_data = create_data_batches(X_val, y_val, valid_data=True)

train_data.element_spec, val_data.element_spec

"""## Visualizando Lotes de Datos

Nuestros datos ahora están en lotes; sin embargo, a veces pueden ser difíciles de entender. Vamos a visualizarlos.
"""

def view_data_batch(images, labels):
  """
    Receives and displays half a batch of images and their labels.

  """

  fig, axes = plt.subplots(4, 4, figsize=(10,10))

  axes = axes.flatten()

  for i in range(16):
    for i, ax in enumerate(axes):
      ax.imshow(images[i])
      ax.set(
          title=unique_breeds[labels[i].argmax()],
          xticks=[],
          yticks=[]
      )

  plt.tight_layout()
  plt.show()

train_images, train_labels = next(train_data.as_numpy_iterator())
view_data_batch(train_images, train_labels)

# Let's now visualize our validation set
val_images, val_labels = next(val_data.as_numpy_iterator())

view_data_batch(val_images, val_labels)

"""## Construyendo un Modelo

Antes de construir un modelo, hay algunas cosas que necesitamos definir:
* La forma de entrada (la forma de nuestras imágenes, en forma de tensores) para nuestro modelo.
* La forma de salida (etiquetas de imágenes, en forma de tensores) de nuestro modelo.
* La URL del modelo que queremos usar.
"""

# Setup input shape to our model
INPUT_SHAPE =  [None, IMG_SIZE, IMG_SIZE, 3]

# Setup output shape
OUTPUT_SHAPE = len(unique_breeds)

# Setup model URL from TensorFlow Hub
MODEL_URL = "https://www.kaggle.com/models/google/mobilenet-v2/tensorFlow2/130-224-classification/1"

"""Ahora que tenemos nuestras entradas, salidas y el modelo listos, ¡juntemos todo en un modelo de deep learning con Keras!

Sabiendo esto, creemos una función que:
* Tome como parámetros la forma de entrada, la forma de salida y el modelo que hemos elegido.
* Defina las capas en un modelo de Keras de forma secuencial (haz esto primero, luego esto, luego aquello).
* Compile el modelo (indica cómo debe evaluarse y mejorarse).
* Construya el modelo (le especifica la forma de entrada que recibirá).
* Devuelva el modelo.

"""



def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):
  print("Building model with: ", model_url)
  # Setup the model layers
  model = tf_keras.Sequential([
      hub.KerasLayer(model_url), # Layer 1 (input layer)
      tf_keras.layers.Dense(units=output_shape,
                            activation="softmax") # Layer 2 (output layer)
  ])

  # Compile the model
  model.compile(
      loss=tf_keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)
      optimizer=tf_keras.optimizers.Adam(), # A friend telling our model how to improve its guesses
      metrics=["accuracy"] # We'd like this to go up
      )  # Build the model

  model.build(input_shape)   # Let the model know what kind of inputs it'll be getting


  return model

model = create_model()
model.summary()

"""## Creando Callbacks

Los *callbacks* son funciones auxiliares que un modelo puede usar durante el entrenamiento para cosas como guardar su progreso, verificar su estado o detener el entrenamiento temprano si deja de mejorar.

Crearemos dos callbacks: uno para **TensorBoard**, que ayuda a rastrear el progreso del modelo, y otro de **early stopping**, que evita que el modelo entrene por demasiado tiempo.

### Callback de TensorBoard

Para configurar un callback de TensorBoard necesitamos hacer tres cosas:

1. Cargar la extensión de cuaderno de TensorBoard ✅  
2. Crear un callback de TensorBoard que pueda guardar *logs* en un directorio y pasarlo a la función `fit()` de nuestro modelo.  
3. Visualizar la pérdida de entrenamiento del modelo con la función mágica `tensorboard` (lo haremos después del entrenamiento del modelo).
"""

# Commented out IPython magic to ensure Python compatibility.
# Load Tensorboard Notebook Extension
# %load_ext tensorboard

import datetime
import os

# Create a function  to build Tensorboard callback
def create_tensorboard_callback():
  # Create a log directory for storing TensorBoard logs
  logdir = os.path.join("drive/MyDrive/Dog Vision/logs",
                        # Make it so the logs get tracked whenever we run an experiment
                        datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))

  return tf_keras.callbacks.TensorBoard(logdir)

"""### Callback de Early Stopping

El *early stopping* ayuda a evitar que nuestro modelo caiga en sobreajuste deteniendo el entrenamiento si una métrica de evaluación determinada deja de mejorar.

https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping?hl=es

"""

# Create early stopping callback
early_stopping = tf_keras.callbacks.EarlyStopping(monitor="val_accuracy",
                                                   patience=3)



"""## Entrenando un modelo (en un subconjunto de datos)

Nuestro primer modelo solo se entrenará con 1000 imágenes para asegurarnos de que todo esté funcionando.

"""

NUM_EPOCHS = 100 #@param {type:"slider", min:10, max:100}

# Check to make sure we're still running on a GPU

print("GPU", "Available YES!" if tf.config.list_physical_devices("GPU") else "not available ):")

"""Ahora creemos una función que entrene un modelo.

* Crear un modelo usando `create_model()`.
* Configurar un callback de TensorBoard usando `create_tensorboard_callback()`.
* Llamar a la función `fit()` de nuestro modelo pasando los datos de entrenamiento, los datos de validación, el número de épocas a entrenar `(NUM_EPOCHS)` y los callbacks que queremos usar.
* Devolver el modelo.
"""

# Build a function to train and return the trained model

def train_model():
  """
  Trains a given model and returns the trained version.
  """
  # Create a model
  model = create_model()

  # Create a new Tensorboard session everytime we train a model
  tensorboard = create_tensorboard_callback()

  # Fit the model to the data passing it the callbacks we created
  model.fit(
      x=train_data,
      epochs=NUM_EPOCHS,
      validation_data=val_data,
      validation_freq=1,
      callbacks=[tensorboard, early_stopping]
  )

  # return the fitted model
  return model

# Fit the model to the data
model = train_model()

"""**Pregunta**: Parece que nuestro modelo está cayendo en sobreajuste porque tiene un desempeño mucho mejor en el conjunto de entrenamiento que en el conjunto de validación. ¿Exploremos algunas formas de prevenir el sobreajuste en redes neuronales profundas?

**Nota**: ¡El sobreajuste al inicio es algo bueno! Significa que nuestro modelo está aprendiendo.

### Revisando los registros de TensorBoard

La función mágica de TensorBoard (`%tensorboard`) accederá al directorio de *logs* que creamos anteriormente y visualizará su contenido.
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir drive/MyDrive/Dog\ Vision/logs

"""### Making and evaluating predictions using a trained model"""

val_data

predictions = model.predict(val_data, verbose=1)
predictions

predictions.shape

len(y_val)

len(y_val)

len(predictions[0])

np.sum(predictions[0])

# First Prediction
print(predictions[0])
print(f"Max value (probability of prediction): {np.max(predictions[0])}")
print(f"Sum: {np.sum(predictions[0])}")
print(f"Max index: {np.argmax(predictions[0])}")
print(f"Predicted label: {unique_breeds[np.argmax(predictions[0])]}")

"""Tener la funcionalidad anterior es genial, pero queremos poder hacerlo a gran escala.

¡Y sería aún mejor si pudiéramos ver la imagen sobre la cual se está haciendo la predicción!  
**Nota**: Las probabilidades de predicción también se conocen como niveles de confianza.
"""

# Turn prediction probabilitoes into their respective label (Easier to understand)


def get_pred_label(prediction_probabilities):
  """
  Turns an array of prediction probabilities into a label (Dog breed).

  Example:
    pred_label = get_pred_label(predictions[0])
    pred_label
  """

  return unique_breeds[np.argmax(prediction_probabilities)]


# Get a predicted label based on an array of prediction probabilities



"""Ahora, como nuestros datos de validación aún están en un conjunto por lotes, tendremos que "desagruparlos" para obtener predicciones sobre las imágenes de validación y luego comparar esas predicciones con las etiquetas de validación (etiquetas reales)."""

val_data

# Create a function to unbatch a dataset

def unbatchify(data):
  """
    Takes a batched dataset of (image, label) Tensors and returns separate arrays of images and labels.
  """

  images = []
  labels = []


  # Loop Through unbatched data
  for image, label in data.unbatch().as_numpy_iterator():
    images.append(image)
    labels.append(
        unique_breeds[np.argmax(label)]
    )

  return images, labels


val_images, val_labels = unbatchify(val_data)
val_images[0], val_labels[0]

"""Ahora tenemos formas de obtener:
- Etiquetas de predicción
- Etiquetas de validación (etiquetas reales)
- Imágenes de validación

Hagamos algunas funciones para visualizar todo esto un poco mejor.

Crearemos una función que:
- Tome un arreglo de probabilidades de predicción, un arreglo de etiquetas reales y un arreglo de imágenes e enteros.
- Convierta las probabilidades de predicción en una etiqueta predicha.
- Grafique la etiqueta predicha, su probabilidad predicha, la etiqueta real y la imagen objetivo en una sola gráfica.

"""

def plot_pred(prediction_probabilities, true_labels, images, n=1):
  """
  View the prediction, ground truth and image for sample n.
  """

  pred_prob, true_label, image = prediction_probabilities[n], true_labels[n], images[n]


  # Get the pred label
  pred_label = get_pred_label(pred_prob)


  color="green" if pred_label == true_label else "red"

  # Plot image & remove ticks
  plt.imshow(image)
  plt.xticks([])
  plt.yticks([])

  plt.title(

            "{} {:2.0f}% {}".format(pred_label, np.max(pred_prob)*100, true_label),
            color=color
  )

plot_pred(
    prediction_probabilities=predictions,
    true_labels=val_labels,
    images=val_images,
    n=11
)

"""Ahora que tenemos una función para visualizar la predicción, hagamos otra para ver las 10 mejores predicciones de nuestro modelo.

Esta función:
- Tomará como entrada las probabilidades de predicción, un arreglo de etiquetas verdaderas y un entero.
- Encontrará la predicción usando `get_pred_label()`.
- Hallará el top 10 de:
  - Índices de las probabilidades de predicción
  - Valores de las probabilidades de predicción
  - Etiquetas de predicción
- Graficará los 10 valores de probabilidad de predicción principales y sus etiquetas, coloreando de verde la etiqueta verdadera.

"""

def plot_pred_conf(prediction_probabilities, labels, n=1):
  """
  Plots the top n highest prediction confidences along with the truth label for sample n.
  """

  pred_prob, true_label = prediction_probabilities[n], labels[n]

  # Get the predicted label
  pred_label = get_pred_label(pred_prob)

  # Find the top 10 prediction confidence indexes
  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]

  # Find the top 10 prediction confidence values
  top_10_pred_values = pred_prob[top_10_pred_indexes]

  # Find the top 10 prediction labels
  top_10_pred_labels = unique_breeds[top_10_pred_indexes]

  # Setear plot
  top_plot = plt.bar(
      np.arange(len(top_10_pred_labels)),
      top_10_pred_values,
      color="grey",
  )


  plt.xticks(
      np.arange(len(top_10_pred_labels)),
      top_10_pred_labels,
      rotation="vertical"
  )


  # Set the title
  if np.isin(pred_label, top_10_pred_labels):
    top_plot[np.argmax(top_10_pred_labels == pred_label)].set_color("green")
    plt.title(f"Predicted: {pred_label} | Truth: {true_label}")
  else:
    pass

plot_pred_conf(predictions, val_labels, n=9)

# Let's check out a few predictions and their different values
i_multiplier = 10
num_rows = 3
num_cols = 2
num_images = num_rows*num_cols

plt.figure(figsize=(10*num_cols, 5*num_rows))

for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_pred(prediction_probabilities=predictions,
            true_labels=val_labels,
            images=val_images,
            n=i+i_multiplier
            )
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_pred_conf(prediction_probabilities=predictions,
                 labels=val_labels,
                 n=i+i_multiplier
                 )
plt.tight_layout(h_pad=1.0)
plt.show()

"""### Guardando y Recargando un modelo entrenado"""

# Create a function to save a model
def save_model(model, suffix=None):
  """
  Saves a given model in a models directory and appends a suffix (str) for clarity.
  """
  # Create a model directory pathname with current time.

  modeldir = os.path.join("drive/MyDrive/Dog Vision/models",
                          datetime.datetime.now().strftime("%Y%m%d-%H%M%s"))

  model_path = modeldir + "-" + suffix + ".h5" # Save format of model
  print(f"Saving moodel to: {model_path}...")
  model.save(model_path)

  return model_path

# Create a function to load a trained model

def load_model(model_path):
  """
  Loads a saved model from a specified path.
  """
  print(f"Loading saved model from: {model_path}")

  model = tf_keras.models.load_model(model_path,
                                     custom_objects={"KerasLayer":hub.KerasLayer})

  return model

"""Ahora que tenemos funciones, usemoslas!"""

# Save our model trained on 1000 images
save_model(model, suffix="1000-images-mobilenetv2-Adam")

# Load a trained model
loaded_1000_image_model = load_model("drive/MyDrive/Dog Vision/models/20250819-18251755627951-1000-images-mobilenetv2-Adam.h5")

model.evaluate(val_data)

loaded_1000_image_model.evaluate(val_data)

"""## Entrenando un modelo supergrande"""

len(X), len(y)

X[:10]

# Create a data batch with the full dataset.

full_data = create_data_batches(X, y)

full_data

# Create a model for full model
full_model = create_model()

# Create full model callbacks
full_model_tensorboard = create_tensorboard_callback()
# No bvalidation set when training all the data, so we can't onitor validation accuracy

full_model_early__stopping = tf_keras.callbacks.EarlyStopping(monitor="accuracy",
                                                             patience=3)
full_model.fit(
    x=full_data,
    epochs=NUM_EPOCHS,
    callbacks=[full_model_tensorboard, full_model_early__stopping]
)

"""## Haciendo predicciones en el conjunto de prueba

Como nuestro modelo se ha entrenado con imágenes en forma de lotes de tensores, para hacer predicciones sobre los datos de prueba debemos usar el mismo formato.

Por suerte, antes creamos `create_data_batches()`, que puede tomar una lista de nombres de archivo como entrada y convertirlos en lotes de tensores.

Para hacer predicciones en los datos de prueba, vamos a:
- Obtener los nombres de archivo de las imágenes de prueba.
- Convertir los nombres de archivo en lotes de datos de prueba usando `create_data_batches()` y estableciendo el parámetro `test_data` en `True` (ya que los datos de prueba no tienen etiquetas).
- Crear un arreglo de predicciones pasando los lotes de prueba al método `predict()` del modelo.

"""

save_model(full_model, suffix="full-image-set-mobilenetv2-Adam")

full_model_loaded =  load_model("drive/MyDrive/Dog Vision/models/20250819-19011755630086-full-image-set-mobilenetv2-Adam.h5")

test_path = "drive/MyDrive/Dog Vision/test"
test_filenames = [test_path + "/" + fname for fname in os.listdir(test_path)]
test_filenames[:10]

test_data = create_data_batches(test_filenames, test_data=True)

test_data

test_data

"""**Nota**: Llamar a `predict()` en nuestro modelo completo y pasarle el lote de datos de prueba tomará mucho tiempo en ejecutarse (alrededor de 1 hora)."""

# Make predictions on test data batch using the loaded full model
test_predictions = full_model_loaded.predict(test_data, verbose=1)

import seaborn as sns
from sklearn.metrics import confusion_matrix

#np.savetxt("drive/MyDrive/Dog Vision/test_predictions.csv", test_predictions, delimiter=",")

test_predictions = np.loadtxt("drive/MyDrive/Dog Vision/test_predictions.csv", delimiter=",")

test_predictions.shape

"""### Preparando las predicciones del conjunto de prueba para Kaggle

Al revisar el ejemplo de envío de Kaggle, vemos que requiere que las salidas de probabilidades de predicción de nuestro modelo estén en un DataFrame con una columna **ID** y una columna para **cada** raza de perro.

https://www.kaggle.com/c/dog-breed-identification/overview/evaluation

Para obtener los datos en este formato, haremos lo siguiente:
* Crear un DataFrame de **pandas** con una columna **ID** y una columna para cada raza de perro.
* Agregar datos a la columna **ID** extrayendo los **ID** de las imágenes de prueba desde sus rutas de archivo.
* Agregar datos (las **probabilidades de predicción**) a cada una de las columnas de razas de perro.
* Exportar el DataFrame como **CSV** para enviarlo a Kaggle.
"""

# Create a pandas DataFrame with empty columns
preds_df = pd.DataFrame(columns=["id"] + list(unique_breeds))

# Append test image IDs to the dataFrame
test_ids = [os.path.splitext(path)[0] for path in os.listdir(test_path)]

test_ids[:10]

preds_df["id"] = test_ids

# Add the prediction probabilities to each dog breed column
preds_df[list(unique_breeds)] = test_predictions

preds_df

# Save the predictions df for submission to kaggle
preds_df.to_csv("drive/MyDrive/Dog Vision/full_model_preds_submit_01.csv", index=False)

"""## Haciendo predicciones en imágenes personalizadas

Para hacer predicciones en imágenes personalizadas vamos a:
- Obtener las rutas de archivo de nuestras propias imágenes.
- Convertir las rutas de archivo en lotes de datos usando `create_data_batches()`. Y como nuestras imágenes personalizadas no tendrán etiquetas, establecemos el parámetro `test_data` en `True`.
- Pasar el lote de datos de imágenes personalizadas al método `predict()` de nuestro modelo.
- Convertir las probabilidades de salida de las predicciones en etiquetas de predicción.
- Comparar las etiquetas predichas con las imágenes personalizadas.

"""

# Get custom image filepaths

custom_path = "drive/MyDrive/Dog Vision/my-dog-photos"
custom_image_paths = [custom_path + "/" + fname for fname in os.listdir(custom_path)]

custom_image_paths

# Turn custom images into batch dataset

custom_data = create_data_batches(custom_image_paths, test_data=True)
custom_preds = full_model_loaded.predict(custom_data)

# Preds
list(map(get_pred_label, custom_preds))

# Get custom images (our unbatchify function won't work, since there aren't labels)
custom_images =  []

for image in custom_data.unbatch().as_numpy_iterator():
  custom_images.append(image)

# Check custom image predictions
plt.figure(figsize=(10, 10))
for i, image in enumerate(custom_images):
  plt.subplot(1, 3, i+1)

  plt.xticks([])
  plt.yticks([])

  plt.title(list(map(get_pred_label, custom_preds))[i])
  plt.imshow(image)